<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>Setup SPARK Environment Locally for Big Data Development - Herman-blog</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="Icaurs - Hexo Theme"><meta name="msapplication-TileImage" content="/img/favicon1.ico"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="Icaurs - Hexo Theme"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta description="Spark has been reported to be one of the most valuable tech skills to learn by data professionals and demand for Spark and Big Data skill has exploded in recent years. As one of the latest technologie"><meta property="og:type" content="blog"><meta property="og:title" content="Setup SPARK Environment Locally for Big Data Development"><meta property="og:url" content="https://hermanteng19.github.io/2021/02/27/Setup-SPARK-Environment-Locally-for-Big-Data-Development/"><meta property="og:site_name" content="Herman-blog"><meta property="og:description" content="Spark has been reported to be one of the most valuable tech skills to learn by data professionals and demand for Spark and Big Data skill has exploded in recent years. As one of the latest technologie"><meta property="og:locale" content="en_US"><meta property="og:image" content="https://hermanteng19.github.io/img/sparkpythonribbon.jpg"><meta property="article:published_time" content="2021-02-27T21:51:47.000Z"><meta property="article:modified_time" content="2023-07-05T01:39:38.672Z"><meta property="article:author" content="Herman Teng"><meta property="article:tag" content="spark"><meta property="article:tag" content="pyspark"><meta property="article:tag" content="environment"><meta property="article:tag" content="linux"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="/img/sparkpythonribbon.jpg"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://hermanteng19.github.io/2021/02/27/Setup-SPARK-Environment-Locally-for-Big-Data-Development/"},"headline":"Herman-blog","image":["https://hermanteng19.github.io/img/sparkpythonribbon.jpg"],"datePublished":"2021-02-27T21:51:47.000Z","dateModified":"2023-07-05T01:39:38.672Z","author":{"@type":"Person","name":"Herman Teng"},"description":"Spark has been reported to be one of the most valuable tech skills to learn by data professionals and demand for Spark and Big Data skill has exploded in recent years. As one of the latest technologie"}</script><link rel="canonical" href="https://hermanteng19.github.io/2021/02/27/Setup-SPARK-Environment-Locally-for-Big-Data-Development/"><link rel="icon" href="/img/favicon1.ico"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.12.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-dark.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css"><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script><meta name="generator" content="Hexo 5.2.0"></head><body class="is-3-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/avatar1.png" alt="Herman-blog" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item is-hidden-tablet catalogue" title="Catalogue" href="javascript:;"><i class="fas fa-list-ul"></i></a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main"><div class="card"><div class="card-image"><span class="image is-7by3"><img class="fill" src="/img/sparkpythonribbon.jpg" alt="Setup SPARK Environment Locally for Big Data Development"></span></div><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2021-02-27T21:51:47.000Z" title="2021-02-27T21:51:47.000Z">2021-02-27</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-07-05T01:39:38.672Z" title="2023-07-05T01:39:38.672Z">2023-07-04</time></span><span class="level-item"><a class="link-muted" href="/categories/IT/">IT</a></span><span class="level-item">8 minutes read (About 1231 words)</span></div></div><h1 class="title is-3 is-size-4-mobile">Setup SPARK Environment Locally for Big Data Development</h1><div class="content"><p>Spark has been reported to be one of the most valuable tech skills to learn by data professionals and demand for Spark and Big Data skill has exploded in recent years. As one of the latest technologies in the big data space, Spark is quickly becoming one of the most powerful Big Data tools for data processing and machine learning, its ability to run programs up to 100x faster than Hadoop MapReduce in memory. </p>
<p>Unlike single program installation, Spark environment setup is not that straight forward but needs a series of installations and configurations with sequence order requirement and dependencies from operating system to software. The main purpose of Spark is dealing with Big Data which means data is too big to allocate into a single server but multiple servers to comprise cluster. Because it’s cluster environment so that Spark is naturally installed in Linux server, therefore, from the operating system perspective, Linux is the only option, which decide the entire process is going to heavy rely on CLI instead of GUI so that the basic Linux CLI command is required before rolling up your sleeves and get your hand dirty.</p>
<p>But if you don’t want to setup environment by yourself, there is also a good solution provided by Databrick. Databrick is a company started by the creator of Spark that provides clusters that run on the top of AWS and adds a convience of having a notebook system already set up and the ability to quickly add files either from storage like Amazon S3 or from your local computer. I has a free community version that supports a 6 GB cluster. Because it is a web-based service so that you can easily follow the wizard on Databrick web portal to finish setup. We don’t show that here because it’s out of our scope.</p>
<p>Before we begin, something is very necessary to emphasis here. Spark is written by Scala, Scala is written by Java, so we have to follow the sequence to make sure Java installed then followed by Scala. Now let’s start it.</p>
<a id="more"></a>

<h2 id="JDK-Java-Installation"><a href="#JDK-Java-Installation" class="headerlink" title="JDK (Java) Installation"></a>JDK (Java) Installation</h2><p>Use below command check if Java 8 or above is in your system, if yes, then we can go directly install <code>Scala</code>.</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Java --version</span><br></pre></td></tr></table></figure>

<p><img src="/img/screenshots/chkjavaversion.png" alt="chkjavaversion.png"></p>
<p>Openjdk version has to be 1.8.0 or higher. If JDK not installed, we have to install Java first.</p>
<p>From Oracle official website download the openJDK source file <code>jdk-8u161-linux-x64.tar.gz</code> to put it in Home directory, create a new directory at <code>/usr/local/java</code>, use <code>tar</code> command to uncompress java files into it.</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /usr/<span class="built_in">local</span></span><br><span class="line">mkdir java</span><br><span class="line"><span class="built_in">cd</span> java</span><br></pre></td></tr></table></figure>

<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar -zxv -f ~/jdk-8u161-linux-x64.tar.gz -C ./</span><br></pre></td></tr></table></figure>

<p>Edit <code>/etc/profile</code> file, add JDK into PATH environmental variable at the end of file</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">JAVA_HOME=/usr/<span class="built_in">local</span>/java/jdk1.8.0_161</span><br><span class="line">CLASSPATH=<span class="variable">$JAVA_HOME</span>/lib/</span><br><span class="line">PATH=<span class="variable">$PATH</span>:<span class="variable">$JAVA_HOME</span>/bin</span><br><span class="line"><span class="built_in">export</span> PATH JAVA_HOME CLASSPATH</span><br></pre></td></tr></table></figure>

<p>At last, execute below command to make configuration take effect</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">source</span> /etc/profile</span><br></pre></td></tr></table></figure>

<h2 id="Scala-Installation"><a href="#Scala-Installation" class="headerlink" title="Scala Installation"></a>Scala Installation</h2><p>If you use <code>Ubuntu</code> then Scala installation is very easy because<code>apt</code> repository and its mirror site contains Scala so that you can install it by below command</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get update</span><br><span class="line">sudo apt-get install -y scala</span><br></pre></td></tr></table></figure>

<p>In this case, we use <code>Centos7</code>, we need to download <code>rpm</code> package from Scala website to install it which is very similar with JDK. We have 2 options to do, once is local install; another one is online install but it needs you have a stable network connection.</p>
<h3 id="Local-Install-Scala"><a href="#Local-Install-Scala" class="headerlink" title="Local Install Scala"></a>Local Install Scala</h3><p>First thing we need to go to <a target="_blank" rel="noopener" href="https://www.scala-lang.org/download/">https://www.scala-lang.org/download/</a>, download <a target="_blank" rel="noopener" href="https://downloads.lightbend.com/scala/2.13.5/scala-2.13.5.rpm">scala-2.13.5.rpm</a> from Archive</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wget https://downloads.lightbend.com/scala/2.13.5/scala-2.13.5.rpm</span><br></pre></td></tr></table></figure>

<p>To install the package, use the <code>yum localinstall</code> command followed by the path to the package name:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo yum localinstall scala-2.13.5.rpm</span><br></pre></td></tr></table></figure>

<p>or use <code>rpm</code> command</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo rpm -ivh scala-2.13.5.rpm</span><br></pre></td></tr></table></figure>

<p>The <code>-v</code> option tells <code>rpm</code> to show verbose output and <code>-h</code> to show the hash marked progress bar.</p>
<p>If the package depends on other packages that are not installed on the system, <code>rpm</code> will display a list of all missing dependencies. You will have to download and install all dependencies manually.</p>
<p>Instead of downloading and the installing the RPM package locally, you can use the URL to RPM package to solve dependency problem easily.</p>
<h3 id="Online-Install-Scala"><a href="#Online-Install-Scala" class="headerlink" title="Online Install Scala"></a>Online Install Scala</h3><p>Issue <code>yum</code> command with Scala RPM package URL to install online</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo yum localinstall https://downloads.lightbend.com/scala/2.13.5/scala-2.13.5.rpm</span><br></pre></td></tr></table></figure>

<p>or use <code>rpm</code> command</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo rpm -ivh https://downloads.lightbend.com/scala/2.13.5/scala-2.13.5.rpm</span><br></pre></td></tr></table></figure>

<h2 id="SPARK-Installation"><a href="#SPARK-Installation" class="headerlink" title="SPARK Installation"></a>SPARK Installation</h2><p>There is tricky here that the Apache Spark now has two major versions, one is <code>2.4.7</code> which is compatible with python 3.5 or lower version if you use <code>pyspark</code> to write your applications; another one is <code>3.0.2</code> which is compatible with python 3.6 or higher version, so make sure your python version before you download it. In our case, we use python 3.8 so we should choose Spark 3.0.2.</p>
<p>First, let’s go to Spark official download page to download Spark 3.0.2 <a target="_blank" rel="noopener" href="https://spark.apache.org/downloads.html">https://spark.apache.org/downloads.html</a>, install file is a <code>tgz</code> package. We also need switch use to <code>root</code> for the sake of permission by command</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">su - root</span><br><span class="line"><span class="built_in">cd</span> ~</span><br></pre></td></tr></table></figure>

<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wget ftp://mirror.csclub.uwaterloo.ca/apache/spark/spark-3.0.2/spark-3.0.2-bin-hadoop2.7.tgz</span><br></pre></td></tr></table></figure>

<p>Next, we uncompress file to <code>/usr/local/spark</code></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /usr/<span class="built_in">local</span></span><br><span class="line">mkdir spark</span><br><span class="line"><span class="built_in">cd</span> spark</span><br></pre></td></tr></table></figure>

<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar -zxv -f ~/spark-3.0.2-bin-hadoop2.7.tgz -C.</span><br></pre></td></tr></table></figure>

<p>Then, we need to install a small package to use <code>pyspark</code> – <code>py4j</code></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install -y py4j</span><br></pre></td></tr></table></figure>

<p>Last, we need to edit environment variable to add Spark. use vim to edit <code>/etc/profile</code> </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> SPARK_HOME=/usr/<span class="built_in">local</span>/spark</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$SPARK_HOME</span>/bin</span><br><span class="line"><span class="built_in">export</span> PYTHONPATH=<span class="variable">$SPARK_HOME</span>/python:<span class="variable">$PYTHONPATH</span></span><br></pre></td></tr></table></figure>

<p>Now, let’s launch spark-shell by issue command</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">spark-shell</span><br></pre></td></tr></table></figure>

<p><img src="/img/screenshots/spark-shell.png" alt="spark-shell.png"></p>
<h3 id="Config-Spark-for-user"><a href="#Config-Spark-for-user" class="headerlink" title="Config Spark for user"></a>Config Spark for user</h3><p>We still need to do some configurations for user or group other than <code>root</code> because that applies to common situation, first switch back to user</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">su - user_name</span><br></pre></td></tr></table></figure>

<p>Edit user environment variable to add Spark to it, vim open file ~/.bash_profile</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim ~/.bash_profile</span><br></pre></td></tr></table></figure>

<p>add Spark directory to PAH</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> SPARK_HOME=/usr/<span class="built_in">local</span>/spark</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$SPARK_HOME</span>/bin</span><br><span class="line"><span class="built_in">export</span> PYTHONPATH=<span class="variable">$SPARK_HOME</span>/python:<span class="variable">$PYTHONPATH</span></span><br></pre></td></tr></table></figure>

<p>Now, let’s launch <code>pyspark</code> by command <code>pyspark</code></p>
<p><img src="/img/screenshots/pysparklaunch.png" alt="pysparklaunch.png"></p>
<p>You might come across some permission issue when you use <code>pyspark</code> shell or in <code>Jupyter notebook</code>, in this case, issue below command to grant permission</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo chmod 777 /usr/<span class="built_in">local</span>/spark/python</span><br><span class="line">sudo chmod 777 /usr/<span class="built_in">local</span>/spark/python/pyspark</span><br></pre></td></tr></table></figure>

<h3 id="Jupyter-Notebook-and-Jupyter-Lab-configure-for-Pyspark"><a href="#Jupyter-Notebook-and-Jupyter-Lab-configure-for-Pyspark" class="headerlink" title="Jupyter Notebook and Jupyter Lab configure for Pyspark"></a>Jupyter Notebook and Jupyter Lab configure for Pyspark</h3><p>Jupyter notebook provides us a very user-friendly interactive python development environment, there is no exceptional for pyspark, so now let’s do some setup to let <code>pyspark</code> can be run on Jupyter</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> PYSPARK_DRIVER_PYTHON=<span class="string">&quot;jupyter&quot;</span></span><br><span class="line"><span class="built_in">export</span> PYSPARK_DRIVER_PYTHON_OPTS=<span class="string">&quot;notebook&quot;</span></span><br><span class="line"><span class="built_in">export</span> PYSPARK_PYTHON=python3</span><br></pre></td></tr></table></figure>

<p>If you use virtual environment on python3 then value of <code>PYSPARK_PYTHON</code> should be <code>python</code> instead of <code>python3</code>. </p>
<p>Now, we can launch Jupyter notebook to start use spark and pyspark</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jupyter notebook</span><br></pre></td></tr></table></figure>

<p>or Jupyter Lab</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jupyter-lab</span><br></pre></td></tr></table></figure>

<p><img src="/img/screenshots/jupyter-pyspark.png" alt="jupyter-pyspark.png"></p>
</div><div class="article-tags is-size-7 mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/tags/spark/">spark</a><a class="link-muted mr-2" rel="tag" href="/tags/pyspark/">pyspark</a><a class="link-muted mr-2" rel="tag" href="/tags/environment/">environment</a><a class="link-muted mr-2" rel="tag" href="/tags/linux/">linux</a></div><div class="a2a_kit a2a_kit_size_32 a2a_default_style"><a class="a2a_dd" target="_blank" rel="noopener" href="https://www.addtoany.com/share"></a><a class="a2a_button_facebook"></a><a class="a2a_button_twitter"></a><a class="a2a_button_telegram"></a><a class="a2a_button_whatsapp"></a><a class="a2a_button_reddit"></a></div><script src="https://static.addtoany.com/menu/page.js" defer></script></article></div><!--!--><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/2022/05/30/Online-Document-Resume-Deployment-on-Github-Pges-with-Docsify/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">Online Document/Resume Deployment on Github Pges with Docsify</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/2021/01/10/Python-Development-Bootstrap-on-Managing-Environment-and-Packages/"><span class="level-item">Python Development Bootstrap on Managing Environment and Packages</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><div class="card"><div class="card-content"><h3 class="title is-5">Comments</h3><div id="disqus_thread"><noscript>Please enable JavaScript to view the <a target="_blank" rel="noopener" href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript></div><script>var disqus_config = function () {
            this.page.url = 'https://hermanteng19.github.io/2021/02/27/Setup-SPARK-Environment-Locally-for-Big-Data-Development/';
            this.page.identifier = '2021/02/27/Setup-SPARK-Environment-Locally-for-Big-Data-Development/';
        };
        (function() {
            var d = document, s = d.createElement('script');  
            s.src = '//' + 'herman-hexo-blog' + '.disqus.com/embed.js';
            s.setAttribute('data-timestamp', +new Date());
            (d.head || d.body).appendChild(s);
        })();</script></div></div></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1 is-sticky"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar is-rounded" src="/img/avatar1.png" alt="Herman"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">Herman</p><p class="is-size-6 is-block">Data Analyst&amp;Developer</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Toronto, Canada</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/archives"><p class="title">27</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/categories"><p class="title">8</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/tags"><p class="title">76</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/HermanTeng19" target="_blank" rel="noopener">Follow</a></div><div class="level is-mobile"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/HermanTeng19"><i class="fab fa-github"></i></a></div></div></div><div class="card widget" id="toc" data-type="toc"><div class="card-content"><div class="menu"><h3 class="menu-label">Catalogue</h3><ul class="menu-list"><li><a class="level is-mobile" href="#JDK-Java-Installation"><span class="level-left"><span class="level-item">1</span><span class="level-item">JDK (Java) Installation</span></span></a></li><li><a class="level is-mobile" href="#Scala-Installation"><span class="level-left"><span class="level-item">2</span><span class="level-item">Scala Installation</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#Local-Install-Scala"><span class="level-left"><span class="level-item">2.1</span><span class="level-item">Local Install Scala</span></span></a></li><li><a class="level is-mobile" href="#Online-Install-Scala"><span class="level-left"><span class="level-item">2.2</span><span class="level-item">Online Install Scala</span></span></a></li></ul></li><li><a class="level is-mobile" href="#SPARK-Installation"><span class="level-left"><span class="level-item">3</span><span class="level-item">SPARK Installation</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#Config-Spark-for-user"><span class="level-left"><span class="level-item">3.1</span><span class="level-item">Config Spark for user</span></span></a></li><li><a class="level is-mobile" href="#Jupyter-Notebook-and-Jupyter-Lab-configure-for-Pyspark"><span class="level-left"><span class="level-item">3.2</span><span class="level-item">Jupyter Notebook and Jupyter Lab configure for Pyspark</span></span></a></li></ul></li></ul></div></div><style>#toc .menu-list > li > a.is-active + .menu-list { display: block; }#toc .menu-list > li > a + .menu-list { display: none; }</style><script src="/js/toc.js" defer></script></div><div class="column-right-shadow is-hidden-widescreen"></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/avatar1.png" alt="Herman-blog" height="28"></a><p class="is-size-7"><span>&copy; 2024 Herman Teng</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" async></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "This website uses cookies to improve your experience.",
          dismiss: "Got it!",
          allow: "Allow cookies",
          deny: "Decline",
          link: "Learn more",
          policy: "Cookie Policy",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script></body></html>